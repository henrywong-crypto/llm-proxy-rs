# Server configuration
host = "0.0.0.0"
port = 3000

# Provider configuration
# Possible values: "openai", "bedrock"
# If not specified, provider will be determined by the model name
provider = "bedrock"

# OpenAI API key (required if using OpenAI provider)
# This can also be set as an environment variable OPENAI_API_KEY
# openai_api_key = "your-api-key-here"

# Example model mapping for reference:
# - OpenAI models: "gpt-3.5-turbo", "gpt-4", "gpt-4-turbo", etc.
# - Bedrock models: "anthropic.claude-3-sonnet-20240229-v1:0", "amazon.titan-text-express-v1", etc.